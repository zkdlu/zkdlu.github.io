---
layout: post
title: "[ELK] 3. ELK와 Kafka로 Log 관제하기"
description: "Elasticsearch, Logstash, Kibana, Kafka"
date: 2021-01-22 00:00:00
tags: [ELK, Docker, Kafka]
comments: true
share: true
---

아직 ELK에 대한 이해가 부족하여 많이 헷갈린다.

우선 서비스들이 Kafka로 로그를 전송하면 ELK로 Kafka의 로그를 수집하는 시나리오로 동작 시켜 보자.



## ELK를 사용해보도록 하자.

### 1. 도커로 만들어진 ELK 를 사용한다.

```bash
$ git clone https://github.com/deviantony/docker-elk.git
```



### 2. Elasticsearch 설정 변경

x-pack은 보안,알림, 모니터링, 보고, 그래프 기능을 편리한 단일 패키지로 제공하는 유료 서비스라고 하니 지우도록 한다.

```yaml
# elasticsearch/config/elasticsearch.yml
cluster.name: "docker-cluster"
network.host: 0.0.0.0
```



### 3. Kibana 설정 변경

elasticsearch에서 제공하는 rest api를 사용하기 위해 서버 주소가 필요한데, 같은 도커 네트워크에서는 컨테이너 명으로 dns가 설정되니 변경하고, 유료 서비스같은거 안 쓸거니까 elasticsearch 패스워드는 지우도록 한다.

```yml
# kibana/config/kibana.yml
server.name: kibana
server.host: 0.0.0.0
elasticsearch.hosts: [ "http://elk_elasticsearch_1:9200" ]
monitoring.ui.container.elasticsearch.enabled: true
```



### 4. Logstash 설정 변경

elasticsearch의 호스트 정보를 변경한다.

```yaml
# logstash/config/logstash.yml
http.host: "0.0.0.0"
xpack.monitoring.elasticsearch.hosts: [ "http://elk_elasticsearch_1:9200" ]
```



### 5. Logstash 파이프라인 변경

카프카로부터 로그 정보를 수집할거기 때문에 input에 kafka, output은 elasticsearch로 한다.

Kibana에서 데이터를 시각화하기 위해서 Elasticsearch의 index에 저장이 되어야 하므로 index를 설정해준다. Kibana에서 index pattern을 wildcard로 처리가 가능하므로 index정보를 일별로 생성 할 수 있도록 한다.

```json
# logstash/pipeline/logstash.conf
input {
	kafka {
		bootstrap_servers => "kafka-container:9092"
		group_id => "logstash"
		topics => ["logs"]
		consumer_threads => 1
	}
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elk-kafka_elasticsearch_1:9200"
        index => "log-%{+YYYY.MM.dd}"
	}
}
```

